---
title: "getting-started-with-analysePeaks"
output: 
  rmarkdown::html_vignette:
    toc: true
vignette: >
  %\VignetteIndexEntry{getting-started-with-analysePeaks}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

# When do I use this package?
I developed this package when I wanted to compare two protocols to identify binding of a protein. In my case, ChIP-seq and CUT&RUN. I wanted to be able to characterize the peaks which were only identified in one of the two experiments.
## What do I need?
You would need:

* narrow peaks for experiment you want to compare (for example, ChIP-seq and CUT&RUN narrow peaks).

* some annotations you would like to correlate with the peaks (gtf if you want to compare with TSS, ATAC-seq or DNAse peaks if you want to check the accessibility, transcription factor motif binding prediction etc...).
All these files should be in the same folder.
  
# An example step-by-step
## Install and load the packages
```{r, warning = FALSE, message = FALSE}
# Necessary to install/run analysePeak
if (!"devtools" %in% installed.packages()){
install.packages("devtools", repos = "https://stat.ethz.ch/CRAN/")
}
devtools::install_github("lldelisle/usefulLDfunctions")
library(usefulLDfunctions)
options(repos = "https://stat.ethz.ch/CRAN/")
safelyLoadAPackageInCRANorBioconductor("GenomicRanges")
safelyLoadAPackageInCRANorBioconductor("rtracklayer")
safelyLoadAPackageInCRANorBioconductor("combinat")
safelyLoadAPackageInCRANorBioconductor("BiocGenerics")
devtools::install_github("lldelisle/usefulLDfunctionsGR")
library(usefulLDfunctionsGR)
safelyLoadAPackageInCRANorBioconductor("reshape")
safelyLoadAPackageInCRANorBioconductor("pheatmap")
devtools::install_github("lldelisle/analysePeaks")
library(analysePeaks)
# Will be used in this tutorial to display overlaps
safelyLoadAPackageInCRANorBioconductor("UpSetR")
safelyLoadAPackageInCRANorBioconductor("eulerr")

```

## Convert my bed/narrowPeaks in GenomicRanges
For this example, small files with only chr22 have been generated and they are stored in your installed directory. If you want to run your own analysis, put here the path of the folder where are your narrowPeak files.
```{r}
# inputFolder contains the path for the folder with narrowPeaks to compare
inputFolder <- system.file("chr22/", package = "analysePeaks")
```
Usually I work with numbered chromosomes and the chrX but here we will work only with chr22:
```{r}
# myChr contains a vector with chromosomes to which I want to restrict the analysis.
# myChr <- paste0("chr", c(1:22, "X"))
myChr <- "chr22"
```

### First the peaks files:
I first create a vector with all file names of narrowPeak to compare (no folder as it is already stored into `inputFolder`). The name of items will be a short name for each experiment.
```{r}
# allExpeFilesNames contains the names of the files
allExpeFilesNames <- c("ChIP_macs_default_peaks_chr22.narrowPeak.gz",
                       "HiCa_pAG_Rep1_macs_likeATAC_withIgG_peaks_chr22.narrowPeak.gz", 
                       "HiCa_pAG_Rep2_macs_likeATAC_withIgG_peaks_chr22.narrowPeak.gz")
# I put a meaningful name for each file name.
names(allExpeFilesNames) <- c("ChIP",
                              "CUTnRUN_HiCa_Rep1",
                              "CUTnRUN_HiCa_Rep2")
# I will now get the full path for the experiments using the inputFolder variable and the allExpeFilesNames.
allExpeFilesPath <- sapply(allExpeFilesNames, function(fn){file.path(inputFolder, fn)})
```
I will convert them to GenomicRanges and put it into the list `allExpe`
```{r}
allExpe <- lapply(allExpeFilesPath, function(fn){
  # I first simplify the narrowPeak file as by default the output of macs2 can call 2 summits for the same peak and I want only once each peak
  # It will be sorted by score
  gr <- grSortedSimplifiedFromNarrowPeak(fn)
  # I restrict the narrowPeaks to the one falling into the chromosomes I selected.
  gr <- subset(gr, seqnames %in% myChr)
  # I update the object with the chromosomes I selected
  seqlevels(gr) <- myChr
  return(gr)
})
```

### Now, the annotations
I chose, a gtf file to see the correlation with TSS, the fimo output which gives me the putative CTCF binding sites based on the jaspar matrix of motif, and the DNAse peaks provided by ENCODE. Here, again, do not put the folder, just the file names.
```{r}
# Put here the name of the files
allAnnotationFilesNames <- c("Homo_sapiens.GRCh37.87_chr22_exons.gtf.gz",
                             "fimo_hg19_CTCF_jaspar_chr22.bed.gz",
                             "GSM816655_hg19_wgEncodeOpenChromDnaseK562PkV2_chr22.narrowPeak.gz")
# Give them a meaningful short name
names(allAnnotationFilesNames) <- c("Genes",
                                    "CTCFmotif",
                                    "DNase")
# This will get the full path:
allAnnotationFilesPath <- sapply(allAnnotationFilesNames, function(fn){file.path(inputFolder, fn)})

```

I will convert them to GenomicRanges and put it into the list `allAnnot`
```{r}
# allAnnot will contains GRanges of each annotation file
allAnnot <-list()
# For TSS we use the function getTSSinUCSCFormatFromEnsemblGTF (which also work if the gtf is already in UCSC format).
allAnnot[["TSS"]] <- getTSSinUCSCFormatFromEnsemblGTF(allAnnotationFilesPath[["Genes"]])
# For bed files we use import.bed
allAnnot[["CTCFmotif"]] <- import.bed(allAnnotationFilesPath[["CTCFmotif"]])
# For narrowPeak we use grSortedSimplifiedFromNarrowPeak to avoid duplicated entries.
allAnnot[["DNase"]] <- grSortedSimplifiedFromNarrowPeak(allAnnotationFilesPath[["DNase"]])
# For each of the annotation, we subset to the chosen chromosomes.
allAnnot <- lapply(allAnnot, function(gr){
  gr <- subset(gr, seqnames %in% myChr)
  seqlevels(gr) <- myChr
  return(gr)
})
```

## Evaluate all useful and interesting overlaps
There are mainly 2 ways to evaluate the overlaps.
```{bash eval=FALSE}
sample 1      ----peak1a----     ----peak1b---                     --peak1c--               ----peak1d---
sample 2            ------------------peak2a---------------------              ---peak2b---      ---peak2c---
sample 3 --peak3a--                                                                           --peak3b--
```

- You want to have a one-to-one overlap: each shared peak in sample 1 should have maximum one corresponding shared peak in sample 2 and maximum one corresponding shared peak in sample 3. This allow to make real Venn diagram: the number of shared peaks between sample 1 and sample 2 is the same in sample 1 and in sample 2. 
  - With 2 samples: When multiple peaks of one experiment overlap one or more peaks from the second, we need to make an arbitrary choice. I decided to put together the peaks with the highest scores. For example, if peak1a has a higher score than peak1b, the pairing would be peak1a with peak2a, peak1d with peak2c. peak1b and peak1c would be specific to sample 1 and peak2b specific to sample 2. 
  - With 3 samples: I decided to put together only peaks that all overlap: peak2a will not be shared with peak3a even if they both overlap peak1a. Then depending on the scores we could have peak1a with peak2a, peak1b and peak 3a specific, or peak1a with peak3a and peak1b with peak2a. This method is time consuming because when you have more than 2 samples it can be tricky to find the best combination.
- The other approach is if you want to have in the specific peaks only the peaks which does not overlap at all any of the peak of the other condition. This is much more faster but then the number of shared peaks do not match. 
  - In the above example, only peak1c and peak2b would be specific. There will be one cluster with peak1a, peak1b, peak2a, and peak3a and one cluster with peak1d, peak2c, and peak3b. So there will be 3 shared peaks in sample 1 corresponding to 2 shared peaks in sample 2. 
  - In addition, peak3a will be considered as overlapping peak2a even if there is no overlap between them. This choice was made because usually you are interested in the overlap between replicates compared to another dataset, so even if the representent of the "overlap between replicates" that would be sample 1 and sample2 is peak2a, you may not want to say that peak2a is specific to the "overlap between replicates" as peak1a overlap peak3a.
  <!-- - In the downstream analysis, only the member of the cluster with the highest score will be used. For example, in sample 1, there will be 2 shared peaks (peak1a and peak1d) and in sample 2, peak2a and peak2c. -->

```{r}
# mySamplesToCheckList contains all combination you want to find overlap.
# It is a list and each item is a vector with all names of experiment you want to compare
mySamplesToCheckList <- list(c("CUTnRUN_HiCa_Rep1", "CUTnRUN_HiCa_Rep2"),
                             c("ChIP", "CUTnRUN_HiCa_Rep2"),
                             c("ChIP", "CUTnRUN_HiCa_Rep1", "CUTnRUN_HiCa_Rep2"))
```


### Using the one-to-one overlaps
The function `findAllOverlap` will generate all pairwise comparisons and will merge them using all possible permutations. This operation may be very long when you have more than 5 experiments to overlap because you have 24 possible permutations and 120 permutations if you have 6...
Then, to end up with a dataframe which will represent the overlaps where each peak is present only once, you use `filterByScore`. This will use the sum of the scores of each peak present in the overlap to choose the overlaps to keep.
The filtered dataframe is stored in ovF with the name of the samples separated by `____`.
```{r, message=FALSE}
# ovAll is a list and will contain all the comparison already computed
# each item of the list will be a dataframe with all possible overlap between items of the experiments
# one item of an experiment can be present in multiple lines if it overlap with multiple items of another experiment
# or if the item with which it overlaps overlap itself multiple experiment etc...
ovAll <- list()
# ovF is a list and will contain all the filtered overlaps.
# each item of the list will be a dataframe where each item of the experiment will be present only once.
ovF <- list()
# For each vector in mySamplesToCheckList
for (samplesToCheck in mySamplesToCheckList){
  # The overlap are only computed if there are at least 2 elements
  if (length(samplesToCheck) > 1){
    # The name of the comparison is the name of the samples separated by ____
    nameOfComp <- paste(sort(samplesToCheck), collapse = "____")
    # We first check if the comparison has not already been calculated
    if (!nameOfComp %in% names(ovF)){
      # compGR contains a list of GRanges with only the samplesToCheck
      compGR <- subsetByNamesOrIndices(allExpe, samplesToCheck)
      # all overlaps are computed (this can be quite long if you have more than 3 experiments in your comparison)
      ovAll <- findAllOverlap(compGR,
                              verbose = T,
                              allMergedCalculated = ovAll,
                              returnAllMergedCalculated = T)
      # the "final" overlap is computed filtering by score.
      ovF[[nameOfComp]] <- filterByScore(compGR,
                                         mAll = ovAll[[nameOfComp]])
    }
  }
}

# As the evaluation of ovAll and ovF can be quite long. It can be useful to store these objects:
#  folderWithCalculatedOverlaps <-"a path with a folder of your choice"
#  saveRDS(ovAll, paste0(folderWithCalculatedOverlaps, "/ovAll.rds"))
#  saveRDS(ovF, paste0(folderWithCalculatedOverlaps, "/ovF.rds"))
# If you want to get them, instead of running the for loop, just use:
#  ovAll <- readRDS(paste0(folderWithCalculatedOverlaps, "/ovAll.rds"))
#  ovF <- readRDS(paste0(folderWithCalculatedOverlaps, "/ovF.rds"))

# The name of the comparison used in ovF is put as name in mySamplesToCheckList
names(mySamplesToCheckList) <- sapply(mySamplesToCheckList,
                                      function(samplesToCheck){
                                        paste(sort(samplesToCheck), collapse = "____")
                                      })

```

### Using the simple overlap
```{r}
# ovClusters is a list and will contain all the dataframe summarizing the overlaps by cluster
ovClusters <- list()
# For each vector in mySamplesToCheckList
for (samplesToCheck in mySamplesToCheckList){
  # The overlap are only computed if there are at least 2 elements
  if (length(samplesToCheck) > 1){
    # The name of the comparison is the name of the samples separated by ____
    nameOfComp <- paste(sort(samplesToCheck), collapse = "____")
    # We first check if the comparison has not already been calculated
    if (!nameOfComp %in% names(ovClusters)){
      # compGR contains a list of GRanges with only the samplesToCheck
      compGR <- subsetByNamesOrIndices(allExpe, samplesToCheck)
      # all overlaps are computed (this can be quite long if you have more than 3 experiments in your comparison)
      ovClusters[[nameOfComp]] <- findOverlapAsClusters(compGR)
    }
  }
}

# The name of the comparison used in ovF is put as name in mySamplesToCheckList
names(mySamplesToCheckList) <- sapply(mySamplesToCheckList,
                                      function(samplesToCheck){
                                        paste(sort(samplesToCheck), collapse = "____")
                                      })

```


## Display the overlaps in one-to-one:
### Euler and Venn
Here I generated Euler and Venn diagrams for only few of the comparisons but you could do for all of them.
```{r}
# We attribute a color to each sample (here I chose the one from a rainbow excluding the extremities)
samplesColor <- rainbow(length(allExpe) + 2)[2:(length(allExpe) + 1)]
names(samplesColor) <- names(allExpe)

# I will now produce the Eulerr and Venn diagram.
# If you want to store them in a pdf file:
#  outputFolder <- "a path with a folder of your choice"
#  pdf(paste0(outputFolder, "/VennB.pdf"),
#      title = paste0(nameOfTheComparison, "_Venn"))

# If you want to do it for all, replace 
# for (e in intersect(names(ovF),
#                     names(mySamplesToCheckList)[1:2])){
# by:
# for (e in names(ovF)){
# Here I am only doing for the first and second comparison:
for (e in intersect(names(ovF), 
                    names(mySamplesToCheckList)[1:2])){
  # I extract from ovF the dataframe with the filtered overlaps
  temp.df <- ovF[[e]]
  n <- ncol(temp.df)
  # I create a list with, for each experiment,
  # the number of the raws where an item of this experiment is involved in the overlap.
  listForEulerr <- list()
  for (i in 1:n){
    listForEulerr <- c(listForEulerr, list(which(!is.na(temp.df[, i]))))
  }
  names(listForEulerr) <- colnames(temp.df)
  # We fit the Euler diagram
  fitOfEulerr <- euler(listForEulerr, shape = "ellipse")
  # Select the colors corresponding to the experiments
  fillCol <- samplesColor[colnames(temp.df)]
  # Plot the Euler diagram
  print(plot(fitOfEulerr,
             main = "Euler diagram",
             fills = list(fill = fillCol, alpha = 0.5),
             legend = list(alpha = 1, cex = 0.5), labels = F,
             quantities = list(cex = 0.5)))
  # As the Euler diagram can be sometimes misleading 
  # (with overlaps not represented whereas they are not empty)
  # I also plot the venn diagram
  vennForTheSame <- venn(listForEulerr)
  print(plot(vennForTheSame,
             main = "Venn diagram",
             fills = list(fill = fillCol, alpha = 0.5),
             legend = list(alpha = 1, cex = 0.5), labels = F,
             quantities = list(cex = 0.5)))
}
# If you stored them in a pdf, do not forget to close the pdf:
#  dev.off()

```

### UpSet
Plotting the UpSet representation for the same overlaps:
```{r}
# As for the Euler,
# If you want to store them in a pdf file:
#  outputFolder <- "a path with a folder of your choice"
#  pdf(paste0(outputFolder, "/UpSet.pdf"),
#      title = paste0(nameOfTheComparison, "_UpSet"))
# If you want to do it for all, replace 
# for (e in intersect(names(ovF),
#                     names(mySamplesToCheckList)[1:2])){
# by:
# for (e in names(ovF)){
# Here I am only doing for the first and second comparison:
for (e in intersect(names(ovF), 
                    names(mySamplesToCheckList)[1:2])){
  # I extract from ovF the dataframe with the filtered overlaps
  temp.df <- ovF[[e]]
  n <- ncol(temp.df)
  # I create a list with, for each experiment,
  # the number of the raws where an item of this experiment is involved in the overlap.
  listForEulerr <- list()
  for (i in 1:n){
    listForEulerr <- c(listForEulerr, list(which(!is.na(temp.df[, i]))))
  }
  names(listForEulerr) <- colnames(temp.df)
  # Plot the upset representation
  print(upset(fromList(listForEulerr), order.by = "freq",
              number.angles = 30,
              mainbar.y.label = "Peak intersections",
              sets.x.label = "Peak per experiment",
              text.scale = 0.7))
}
# If you stored them in a pdf, do not forget to close the pdf:
#  dev.off()
```

## Display the overlaps in overlap by cluster:
### Euler and Venn
Here I generated Euler and Venn diagrams for only few of the comparisons but you could do for all of them.
```{r}
# We attribute a color to each sample (here I chose the one from a rainbow excluding the extremities)
samplesColor <- rainbow(length(allExpe) + 2)[2:(length(allExpe) + 1)]
names(samplesColor) <- names(allExpe)

# I will now produce the Eulerr and Venn diagram.
# If you want to store them in a pdf file:
#  outputFolder <- "a path with a folder of your choice"
#  pdf(paste0(outputFolder, "/VennB.pdf"),
#      title = paste0(nameOfTheComparison, "_Venn"))

# If you want to do it for all, replace 
# for (e in intersect(names(ovClusters),
#                     names(mySamplesToCheckList)[1:2])){
# by:
# for (e in names(ovClusters)){
# Here I am only doing for the first and second comparison:
for (e in intersect(names(ovClusters), 
                    names(mySamplesToCheckList)[1:2])){
  # I extract from ovClusters the dataframe with the clusters
  df <- ovClusters[[e]]
  temp.df <- as.data.frame(apply(df, 2, function(l){
    sapply(l, length)
  }))
  colnames(temp.df) <- colnames(df)
  temp.df2 <- as.data.frame(temp.df > 0)
  n <- ncol(temp.df)
  # I create a list with, for each experiment,
  # the number of the raws where an item of this experiment is involved in the overlap.
  listForEulerr <- list()
  for (i in 1:n){
    listForEulerr <- c(listForEulerr, list(which(temp.df[, i] != 0)))
  }
  names(listForEulerr) <- colnames(temp.df)
  # We fit the Euler diagram
  fitOfEulerr <- euler(listForEulerr, shape = "ellipse")
  # Select the colors corresponding to the experiments
  fillCol <- samplesColor[colnames(temp.df)]
  # Plot the Euler diagram
  p <- plot(fitOfEulerr,
            main = "Euler diagram",
            fills = list(fill = fillCol, alpha = 0.5),
            legend = list(alpha = 1, cex = 0.5), labels = F,
            quantities = list(cex = 0.5))
  combinations <- fitOfEulerr$original.values
  p <- plot(fitOfEulerr,
            main = "Euler diagram",
            fills = list(fill = fillCol, alpha = 0.5),
            legend = list(alpha = 1, cex = 0.5), labels = F,
            quantities = list(labels = as.character(1:length(combinations)),
                              cex = 0.5))
  # Where I will put the real quantities both for clusters and peaks numbers:
  for(i in 1:length(combinations)){
    j <- as.numeric(p$children$canvas.grob$children$diagram.grob.1$children$tags$children[[i]]$children[[2]]$label)
    name <- names(combinations)[i]
    if (!grepl("&", name)){
      p$children$canvas.grob$children$diagram.grob.1$children$tags$children[[i]]$children[[2]]$label <- 
        paste(combinations[j], "clusters\n", combinations[j], "peaks")
    } else {
      inOverlap <- strsplit(name, "&")[[1]]
      absentInOverlap <- setdiff(colnames(df), inOverlap)
      if (length(absentInOverlap) == 0){
        cmd <- paste0("with(temp.df, which(", paste(inOverlap, "> 0", collapse = " & "), "))")
      } else {
        cmd <- paste0("with(temp.df, which(", paste(inOverlap, "> 0", collapse = " & "), " & ",
                      paste(absentInOverlap, "== 0", collapse = " & "), "))")
      }
      clusters <- eval(parse(text = cmd))
      peaksNumbers <- colSums(temp.df[clusters, inOverlap])
      p$children$canvas.grob$children$diagram.grob.1$children$tags$children[[i]]$children[[2]]$label <- 
        paste(combinations[j], "clusters\n", paste(peaksNumbers, collapse = ","), "peaks")
    }
  }
  print(p)
  # As the Euler diagram can be sometimes misleading 
  # (with overlaps not represented whereas they are not empty)
  # I also plot the venn diagram
  vennForTheSame <- venn(listForEulerr)
  p <- plot(vennForTheSame,
            main = "Venn diagram",
            fills = list(fill = fillCol, alpha = 0.5),
            legend = list(alpha = 1, cex = 0.5), labels = F,
            quantities = list(labels = as.character(1:length(combinations)),
                              cex = 0.5))
  # Where I will put the real quantities both for clusters and peaks numbers:
  for(i in 1:length(combinations)){
    j <- as.numeric(p$children$canvas.grob$children$diagram.grob.1$children$tags$children[[i]]$children[[2]]$label)
    name <- names(combinations)[i]
    if (!grepl("&", name)){
      p$children$canvas.grob$children$diagram.grob.1$children$tags$children[[i]]$children[[2]]$label <- 
        paste(combinations[j], "clusters\n", combinations[j], "peaks")
    } else {
      inOverlap <- strsplit(name, "&")[[1]]
      absentInOverlap <- setdiff(colnames(df), inOverlap)
      if (length(absentInOverlap) == 0){
        cmd <- paste0("with(temp.df, which(", paste(inOverlap, "> 0", collapse = " & "), "))")
      } else {
        cmd <- paste0("with(temp.df, which(", paste(inOverlap, "> 0", collapse = " & "), " & ",
                      paste(absentInOverlap, "== 0", collapse = " & "), "))")
      }
      clusters <- eval(parse(text = cmd))
      peaksNumbers <- colSums(temp.df[clusters, inOverlap])
      p$children$canvas.grob$children$diagram.grob.1$children$tags$children[[i]]$children[[2]]$label <- 
        paste(combinations[j], "clusters\n", paste(peaksNumbers, collapse = ","), "peaks")
    }
  }
  print(p)
  
}
# If you stored them in a pdf, do not forget to close the pdf:
#  dev.off()
```

### UpSet
Plotting the UpSet representation for the same overlaps:
```{r}
# As for the Euler,
# If you want to store them in a pdf file:
#  outputFolder <- "a path with a folder of your choice"
#  pdf(paste0(outputFolder, "/UpSet.pdf"),
#      title = paste0(nameOfTheComparison, "_UpSet"))
# If you want to do it for all, replace 
# for (e in intersect(names(ovF),
#                     names(mySamplesToCheckList)[1:2])){
# by:
# for (e in names(ovF)){
# Here I am only doing for the first and second comparison:
for (e in intersect(names(ovClusters), 
                    names(mySamplesToCheckList)[1:2])){
  # I extract from ovClusters the dataframe with the clusters
  df <- ovClusters[[e]]
  temp.df <- as.data.frame(apply(df, 2, function(l){
    sapply(l, length)
  }))
  colnames(temp.df) <- colnames(df)
  temp.df2 <- as.data.frame(temp.df > 0)
  n <- ncol(temp.df)
  # I create a list with, for each experiment,
  # the number of the raws where an item of this experiment is involved in the overlap.
  listForEulerr <- list()
  for (i in 1:n){
    listForEulerr <- c(listForEulerr, list(which(temp.df[, i] != 0)))
  }
  names(listForEulerr) <- colnames(temp.df)
  # Plot the upset representation
  print(upset(fromList(listForEulerr), order.by = "freq",
              number.angles = 30,
              mainbar.y.label = "Number of Clusters",
              sets.x.label = "Number of Clusters per experiment",
              text.scale = 0.7))
}
# If you stored them in a pdf, do not forget to close the pdf:
#  dev.off()
```


## Generate some plots for pairwise comparison based on the score rank
The plots for pairwise comparison will assess how well the order (by decreasing score) is conserved between the 2 experiments:
This can also help you to check what is the number of top peaks which maximize the overlap between replicates.
This comparison is not useful if the experiment does not represent the same experiment. For example, if you compare a ChIP of CTCF with a ChIP of GATA1. This is not relevent.
```{r, message=FALSE}
# I change the font size to make it fit in the vignette but you can adjust it:
par(cex = 0.6)
name1 <- "CUTnRUN_HiCa_Rep1"
name2 <- "CUTnRUN_HiCa_Rep2"
# Here the name of the experiment is pretty long and the titles would be ugly...
# To have shorter titles and legend I will rename them to Rep1 and Rep2:
newName1 <- "Rep1"
newName2 <- "Rep2"
# Former name of the experiment:
e <- paste(sort(c(name1, name2)), collapse = "____")
# New name of the experiment:
newE <- paste(sort(c(newName1, newName2)), collapse = "____")
# I duplicate the result in the ovF list
ovF[[newE]] <- ovF[[e]]
# But I need to change the names of the columns:
newColNames <- colnames(ovF[[e]])
newColNames[newColNames == name1] <- newName1
newColNames[newColNames == name2] <- newName2
colnames(ovF[[newE]]) <- newColNames
# I also need to duplicate the experiments in allExperiment
allExpe[[newName1]] <- allExpe[[name1]]
allExpe[[newName2]] <- allExpe[[name2]]

# If your names are already pretty short, or
# You do not want to change them, you just need to 
# put in e the name of the comparison:
# e <- "CUTnRUN_HiCa_Rep1____CUTnRUN_HiCa_Rep2"
# Or get it from the mySamplesToCheckList
# Here it is the first comparison:
# e <- names(mySamplesToCheckList)[1]

# Finally, I can do the comparison...
# Because there is not a lot of peaks, 
# I put step = 200 but for a real dataset, 
# I would put 5000 or 2000 if there is not a lot of peaks.

# If you want to save it is pdf:
#  pdf(paste0(outputFolder, "/", newName1, "vs", newName2, ".pdf"),
#      title = paste0(newName1, "vs", newName2, ".pdf"))
#  plotPairwiseComparison(newName1, newName2, ovF, allExpe, step = 200, fontsize = 6)
#  dev.off()
plotPairwiseComparison(newName1, newName2, ovF, allExpe, step = 200, fontsize = 6)
```

We can also use the same function using the clustering overlap:
```{r}
ovClusters[[newE]] <- ovClusters[[e]]
# But I need to change the names of the columns:
colnames(ovClusters[[newE]]) <- newColNames

plotPairwiseComparison(newName1, newName2, ovClusters, allExpe, step = 200, fontsize = 6)
```


We can see that the replicates are highly correlated (independently on the method used), and the maximum of overlap is obtained for the top 400 peaks.

Let see how the Replicate 2 correlates with the ChIP:
```{r, message=FALSE}
# I change the font size to make it fit in the vignette but you can adjust it:
par(cex = 0.6)
name1 <- "ChIP"
name2 <- "CUTnRUN_HiCa_Rep2"
# Here the name of the experiment is pretty long and the titles would be ugly...
# To have shorter titles and legend I will rename them to Rep1 and Rep2:
newName1 <- "ChIP"
newName2 <- "Rep2"
# Former name of the experiment:
e <- paste(sort(c(name1, name2)), collapse = "____")
# New name of the experiment:
newE <- paste(sort(c(newName1, newName2)), collapse = "____")
# I duplicate the result in the ovF list
ovF[[newE]] <- ovF[[e]]
# But I need to change the names of the columns:
newColNames <- colnames(ovF[[e]])
newColNames[newColNames == name1] <- newName1
newColNames[newColNames == name2] <- newName2
colnames(ovF[[newE]]) <- newColNames
# I also need to duplicate the experiments in allExperiment
allExpe[[newName1]] <- allExpe[[name1]]
allExpe[[newName2]] <- allExpe[[name2]]

# If your names are already pretty short, or
# You do not want to change them, you just need to 
# put in e the name of the comparison:
# e <- "CUTnRUN_HiCa_Rep1____CUTnRUN_HiCa_Rep2"
# Or get it from the mySamplesToCheckList
# Here it is the second comparison:
# e <- names(mySamplesToCheckList)[2]

# Finally, I can do the comparison...
# Because there is not a lot of peaks, 
# I put step = 200 but for a real dataset, 
# I would put 5000 or 2000 if there is not a lot of peaks.


# Because there is not a lot of peaks, 
# I put step = 200 but for a real dataset, 
# I would put 5000 or 2000 if there is not a lot of peaks.

# If you want to save it is pdf:
#  pdf(paste0(outputFolder, "/", newName1, "vs", newName2, ".pdf"),
#      title = paste0(newName1, "vs", newName2, ".pdf"))
#  plotPairwiseComparison(newName1, newName2, ovF, allExpe, step = 200, fontsize = 6)
#  dev.off()
plotPairwiseComparison(newName1, newName2, ovF, allExpe, step = 200, fontsize = 6)
```

We can also use the same function using the clustering overlap:
```{r}
ovClusters[[newE]] <- ovClusters[[e]]
# But I need to change the names of the columns:
colnames(ovClusters[[newE]]) <- newColNames

plotPairwiseComparison(newName1, newName2, ovClusters, allExpe, step = 200, fontsize = 6)
```

We can see that the correlation is highly decreased, one reason is that there is a decreased proportion of overlapping but even in the overlap, the order is not very well conserved.

## Generate plots for Set vs Ref comparison
Now I would like to describe which characteristics of the peaks are specific to one technique or the other.  
For this, I will define a reference (only one experiment), and a Set which can be multiple experiments.  
Let's first try to compare the Replicate 2 CUTnRUN with the ChIP:
```{r}
name1 <- "ChIP"
name2 <- "CUTnRUN_HiCa_Rep2"
e <- paste(sort(c(name1, name2)), collapse = "____")
# We could also get it from the mySamplesToCheckList
# Here it is the second comparison:
# e <- names(mySamplesToCheckList)[2]
```
We define the Ref:
```{r}
myRefName <- "ChIP"
```
The annotations are of 2 categories:

* The one where the highest score overlapping the peak matters.

* The other where the distance to the peak matters.  

The motif and the DNase are in the first category, wherease the TSS is in the other one.
```{r}
# We subset from the full list of annotations (allAnnot), the one where the score is important:
mygrLScores <- subsetByNamesOrIndices(allAnnot, c("CTCFmotif", "DNase"))
# We subset from the full list of annotations (allAnnot), the one where the distance is important:
mygrDistance <- subsetByNamesOrIndices(allAnnot, c("TSS"))
```

We will now annotate the peaks with the annotations:
```{r}
myList <- createMyGRs(e = e, ovF = ovF, allExpe, grLScores = mygrLScores,
                      grLDistance = mygrDistance,
                      nameOfRef = myRefName)
```

We will visualise the values of the annotations to set-up categories:
```{r}
# I change the font size to make it fit in the vignette but you can adjust it:
par(cex = 0.6)
plotClassicalHistogramForMyGRs(myList)
```

We can conclude from these histograms that 

* the CTCF motif scores in the peaks which are specific to only one experiment are decreased.

* the peaks which are specific to the ChIP method are less open (the score of DNase is decreased).

* the peaks which are specific to the CUT&RUN method are slightly more often found at TSS.

Another way to define categories is to use the quartiles:
```{r}
lapply(mygrLScores, function(gr) {quantile(gr$score, c(0, 0.25, 0.5, 0.75, 0.9, 0.95, 0.99, 1))})
```


To help compare, I define the thresholds which will define the categories:
```{r}
# The names of the threshold should match the name of the annotations
mythresholdsForgrLScores = list("CTCFmotif" = c(20,10,0), "DNase" = c(900,600,500,0))
mythresholdsForgrLDistance = list("TSS" = c(20e3,5e3,1e3,0))
```
We now assign each peak to a category:
```{r}
myList2<- annotateWithCate(myList,
                           mythresholdsForgrLScores,
                           mythresholdsForgrLDistance)
```
And plot histograms for each category as well as heatmaps for pairs of categories:
```{r}
# I change the font size to make it fit in the vignette but you can adjust it:
par(cex = 0.6)
plotCateComparisonSetAndRef(myList2, fontsize = 6) 
# If you want to save it in pdf:
#  pdf(paste0(outputFolder,"/setPlotOf",e,".pdf"),title=paste0("setPlotOf",e))
#  plotClassicalHistogramForMyGRs(myList)
#  myList2<- annotateWithCate(myList,
#                             mythresholdsForgrLScores,
#                             mythresholdsForgrLDistance)
#  plotCateComparisonSetAndRef(myList2)  
#  
#  dev.off() 
```

```{r}
# You can also replot heatmaps as proportion:
plotCateComparisonSetAndRef(myList2, plotBarPlots = F, plotProportion = T, fontsize = 6) 
```


The barplots confirm what was shown with histograms but help with the quantification. For example, it shows that the proportion of CUT&RUN peaks with no CTCF motif increase from 10% in the peaks shared with ChIP to 80%. The increase in the ChIP between shared with CUT&RUN and specific is only from 20 to 25%.

The heatmap are really interesting because they better qualify. Most of the peaks which are specific to CUT&RUN tend to have no CTCF binding motif and are either at TSS with high DNase score or with no DNase between 1kb and 20kb of any TSS.

The same analysis can be done using the overlaps by cluster:
```{r}
myList <- createMyGRsUsingSimpleOverlap(mySet = name2, myRef = name1,
                                        ovCluster = ovClusters[[e]], allExpe, grLScores = mygrLScores,
                                        grLDistance = mygrDistance)
par(cex = 0.6)
plotClassicalHistogramForMyGRs(myList)
myList2<- annotateWithCate(myList,
                           mythresholdsForgrLScores,
                           mythresholdsForgrLDistance)
plotCateComparisonSetAndRef(myList2, fontsize = 6) 

```


Here is a comparison where the Set was only one so the notion of specific and shared is quite easy. When the Set is composed of multiple experiments, first the Set peaks are the peaks which are shared between all experiments of the Set. Then, what is specific to the set is quite straight forward (shared between all Set members and shared by the Ref). What is specific to the Ref is defined as not shared by any of the Set members.
When you specify the experiment e, everything except the Ref will be considered as the Set.
For example, we will now compare the ChIP to both replicates of CUT&RUN:
```{r}
# I change the font size to make it fit in the vignette but you can adjust it:
par(cex = 0.6)
# Now we want to use the third comparison of mySamplesToCheckList
e <- names(mySamplesToCheckList)[3]
print(e)
# I keep the reference and the annotations:
myList <- createMyGRs(e = e, ovF = ovF, allExpe, grLScores = mygrLScores,
                      grLDistance = mygrDistance,
                      nameOfRef = myRefName)
plotClassicalHistogramForMyGRs(myList)

```
We still have the same conclusions when we merge the two replicates.
```{r}
# I change the font size to make it fit in the vignette but you can adjust it:
par(cex = 0.6)
# I keep the thresholds:
myList2<- annotateWithCate(myList,
                           mythresholdsForgrLScores,
                           mythresholdsForgrLDistance)
plotCateComparisonSetAndRef(myList2, fontsize = 6) 
```

The same analysis can be done using the overlaps by cluster:
```{r}
myListO <- createMyGRsUsingSimpleOverlap(mySet = c("CUTnRUN_HiCa_Rep1", "CUTnRUN_HiCa_Rep2"), myRef = c("ChIP"),
                                        ovCluster = ovClusters[[e]], allExpe, grLScores = mygrLScores,
                                        grLDistance = mygrDistance)
par(cex = 0.6)
# plotClassicalHistogramForMyGRs(myList)
myList2O<- annotateWithCate(myListO,
                           mythresholdsForgrLScores,
                           mythresholdsForgrLDistance)
plotCateComparisonSetAndRef(myList2O, fontsize = 6) 

```

## Export
You might be interested in exporting the data you generated.  
There are 2 functions in the package to export data:

* `writeNarrowPeaksFromMyGRsAndAnnot` which will write 4 narrowPeak files from an output of createMyGRs:
```{r,  eval=FALSE}
writeNarrowPeaksFromMyGRsAndAnnot(myList, outputDirectory = "./")
# Also working with myListO
writeNarrowPeaksFromMyGRsAndAnnot(myListO, outputDirectory = "./")
```

* `writeTablesFromMyGRsAndAnnot` which will write 2 tables with all evaluated information for each peak from an output of createMyGRs:
```{r,  eval=FALSE}
writeTablesFromMyGRsAndAnnot(myList2, outputDirectory = "./")
# Also working with myList2O
# But as it output the same file names it should be in a different outputDirectory
writeNarrowPeaksFromMyGRsAndAnnot(myList2O, outputDirectory = "./withCluster/")
```



# If you have issues with this package or suggestions...
Feel free to report them on the "issues" area of GitHub [here](https://github.com/lldelisle/analysePeaks/issues) or send me an [email](mailto:lucille.delisle@epfl.ch) and I will open an issue for you.

# Where does the data come from:
## ChIP
The ChIP dataset used is: SRR299298  
The bam was downloaded from the GEO [webpage](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM749690) and peaks were called with macs2:
```{bash, eval=FALSE}
macs2 callpeak -t GSM749690_hg19_wgEncodeUwTfbsK562CtcfStdAlnRep1.bam -n ChIP_macs_default --call-summits -B -f BAM 2> ChIP_macs_default.log
```
## CUT&RUN
The CUT&RUN dataset were the one from the publication [Improved CUT&RUN chromatin profiling tools.](https://www.ncbi.nlm.nih.gov/pubmed/31232687). The bed with mapped reads were downloaded from the GEO [webpage](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3609748) and peaks were called with macs2 using the IgG experiment also available on [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM3609773):
```{bash, eval=FALSE}
inputOfMacs=GSM3609748_K562_CTCF_pAG_hi-Ca_27m_Rep1.hg19.bed.gz
inputBedForC=GSM3609773_K562_IgG_hi-Ca.hg19.bed.gz
for inBED in $inputOfMacs $inputBedForC; do
zcat ${pathForInput}$inBED | awk '{if($0!=prevLine){printf("%s\t%d\t%d\t%s\t%d\t%s\n",$1,$2,$2+10,"R1_"NR,0,"+");printf("%s\t%d\t%d\t%s\t%d\t%s\n",$1,$3-10,$3,"R2_"NR,0,"-");prevLine=$0}}' | gzip > ${inBED}_split.bed.gz
done
macs2 callpeak -t ${inputOfMacs}_split.bed.gz -c ${inputBedForC}_split.bed.gz --nomodel --keep-dup all --shift -100 --extsize 200 -n ${sample}_macs_likeATAC_withIgG --call-summits -B -f BED 2> ${pathResults}${sample}_macs_likeATAC_withIgG.log
```

Then all peaks were restricted to chr22 for the purpose of the vignette:
```{bash, eval=FALSE}
for f in *.narrowPeak; do name=`basename $f .narrowPeak` ; cat $f | awk '$1=="chr22"{print}' | gzip > chr22/${name}_chr22.narrowPeak.gz; done
```

## GTF
The GTF was downloaded from Ensembl [FTP](ftp://ftp.ensembl.org/pub/release-87/gtf/homo_sapiens/Homo_sapiens.GRCh38.87.gtf.gz) this is not the last version as it needed to be compatible with hg19.  
Then only chr22 and first exon were selected:  
`zcat Homo_sapiens.GRCh37.87.gtf.gz | awk '$1=="22" && $3 == "exon" {print}' | grep "exon_number \"1\"" | gzip > chr22/Homo_sapiens.GRCh37.87_chr22_firstexons.gtf.gz`

## DNase
The DNase peaks were downloaded from [GEO](https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSM816655) and reduced to chr22:  
`zcat GSM816655_hg19_wgEncodeOpenChromDnaseK562PkV2.narrowPeak.gz | awk '$1=="chr22"{print}' | gzip > chr22/GSM816655_hg19_wgEncodeOpenChromDnaseK562PkV2_chr22.narrowPeak.gz`

## CTCF binding motif
The MEME matrix for CTCF motif was downloaded from [jaspar](http://jaspar2018.genereg.net/api/v1/matrix/MA0139.1.meme).
Then FIMO was used:  
```{bash, eval=FALSE}
fimo --o fimo_out_CTCF --max-stored-scores 10e6 MA0139.1.meme hg19.fa
cat fimo_out_CTCF/fimo.tsv | awk 'NR>1 && !($1~/#/) && (NF>0) {split($3,a,":|-");print a[1]"\t"a[2]+$4"\t"a[2]+$5"\t"$3"\t"$7"\t"$6}' | gzip > fimo_out_CTCF/fimo_hg19_jaspar.bed.gz
```
Only chr22 were kept:  
`zcat fimo_hg19_jaspar.bed.gz | awk '$1=="chr22"{print}' | gzip > chr22/fimo_hg19_CTCF_jaspar_chr22.bed.gz`
